{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1e01</td>\n",
       "      <td>Hello. Hi. My name is Leslie Knope, and I work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s1e02</td>\n",
       "      <td>Well, one of the funner things that we do here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s1e03</td>\n",
       "      <td>Okay, now, see, here's a good example of a pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s1e04</td>\n",
       "      <td>So, we've been called out to this hiking trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s1e05</td>\n",
       "      <td>In a town as old as Pawnee, there's a lot of h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Episode                                       Episode_Text\n",
       "0   s1e01  Hello. Hi. My name is Leslie Knope, and I work...\n",
       "1   s1e02  Well, one of the funner things that we do here...\n",
       "2   s1e03  Okay, now, see, here's a good example of a pla...\n",
       "3   s1e04  So, we've been called out to this hiking trail...\n",
       "4   s1e05  In a town as old as Pawnee, there's a lot of h..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('episodes.pickle','rb') as read_file:\n",
    "    episodes = pickle.load(read_file)\n",
    "\n",
    "episodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Model With No Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 17378)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "doc_word = vectorizer.fit_transform(episodes.Episode_Text)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madelinevossbrinck/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.31863112, 2.20387707, 2.23150465],\n",
       "       [3.93961158, 2.12028603, 1.60596938],\n",
       "       [3.53329894, 4.2841771 , 0.        ],\n",
       "       [3.17919686, 3.00471073, 1.77920504],\n",
       "       [3.8900341 , 2.13706108, 1.41127637],\n",
       "       [2.24097932, 5.36423713, 0.91918698],\n",
       "       [3.71074046, 4.14868157, 0.27137849],\n",
       "       [2.80173364, 3.04694323, 2.47517043],\n",
       "       [2.70828457, 2.72104876, 1.76220089],\n",
       "       [1.68399457, 6.41058152, 1.31152712],\n",
       "       [4.47995263, 0.3132251 , 1.58648019],\n",
       "       [3.1619122 , 3.8043182 , 0.32944369],\n",
       "       [2.97338922, 3.8399051 , 1.13420041],\n",
       "       [2.88381695, 3.68085148, 2.06972667],\n",
       "       [4.8443509 , 0.9932011 , 0.16594705],\n",
       "       [3.03300647, 4.58524029, 0.        ],\n",
       "       [1.92372338, 3.98909553, 2.46052461],\n",
       "       [3.46854751, 2.85772844, 1.34651549],\n",
       "       [2.34234696, 7.76571527, 2.46021902],\n",
       "       [3.00334972, 3.27202199, 2.11998497],\n",
       "       [3.13093088, 3.52596364, 0.6858832 ],\n",
       "       [1.70824317, 4.61641608, 1.48074252],\n",
       "       [3.61514218, 2.62060422, 1.65425542],\n",
       "       [4.06451158, 3.83216159, 0.45635871],\n",
       "       [4.25443469, 1.13078648, 2.73394079],\n",
       "       [3.88200337, 3.96480618, 0.        ],\n",
       "       [3.19827038, 3.16631363, 1.63536971],\n",
       "       [2.48014079, 2.31989622, 4.72729734],\n",
       "       [3.24920538, 5.76263909, 2.75030129],\n",
       "       [3.36802514, 3.61919025, 2.99870171],\n",
       "       [3.79097329, 2.3426064 , 1.17114209],\n",
       "       [3.33104999, 1.91510122, 2.85079433],\n",
       "       [3.80741819, 2.46464297, 1.64496319],\n",
       "       [2.34025322, 3.61205395, 2.54564588],\n",
       "       [3.93246559, 0.68864345, 3.3345295 ],\n",
       "       [2.34648121, 4.2301449 , 1.80138294],\n",
       "       [5.4856303 , 1.42405634, 1.89225384],\n",
       "       [4.04702597, 1.81369785, 1.54562164],\n",
       "       [1.7652193 , 4.40984432, 3.85194995],\n",
       "       [2.22478461, 3.98887457, 2.17231237],\n",
       "       [4.33986869, 2.0216268 , 4.5675713 ],\n",
       "       [3.28456962, 1.96831171, 3.53951985],\n",
       "       [3.08998202, 3.62217572, 3.60425043],\n",
       "       [3.61760122, 2.48408755, 1.94872371],\n",
       "       [2.55337379, 2.91381814, 3.29403399],\n",
       "       [3.91828374, 4.03711751, 2.46191612],\n",
       "       [1.98283571, 4.77686948, 2.65562465],\n",
       "       [2.86293681, 2.23109827, 3.27519926],\n",
       "       [4.55209647, 1.93730853, 0.10693094],\n",
       "       [3.96560262, 0.89696725, 1.56517849],\n",
       "       [2.96576693, 3.47240424, 1.18263966],\n",
       "       [4.77708182, 2.23116612, 2.52702471],\n",
       "       [3.51550782, 2.47653052, 2.44466189],\n",
       "       [3.4796665 , 1.55386083, 3.07517155],\n",
       "       [3.87161138, 2.62995651, 1.44784187],\n",
       "       [4.07445376, 2.03775456, 2.04058578],\n",
       "       [3.70283729, 2.26486663, 2.53642217],\n",
       "       [4.08131403, 2.62079063, 1.70203751],\n",
       "       [1.89379729, 5.78438968, 1.99166537],\n",
       "       [2.93446744, 3.18415246, 2.9593686 ],\n",
       "       [2.42292344, 4.18887017, 4.91071951],\n",
       "       [3.78714286, 2.20269248, 1.95055489],\n",
       "       [3.58709507, 1.07969091, 3.72988755],\n",
       "       [3.61949745, 2.47430674, 1.91648218],\n",
       "       [4.7136277 , 2.56262034, 0.50572165],\n",
       "       [4.28989492, 1.06064423, 2.6225598 ],\n",
       "       [4.95814466, 0.        , 2.07635482],\n",
       "       [3.50441524, 1.86244349, 2.47856287],\n",
       "       [4.97244063, 0.91700639, 1.48413734],\n",
       "       [2.61557562, 2.4689521 , 3.29343247],\n",
       "       [4.09516104, 0.92011235, 2.85678852],\n",
       "       [4.04250612, 2.07625521, 3.53293664],\n",
       "       [2.84109051, 3.54910292, 1.53453071],\n",
       "       [3.77441451, 3.14077062, 2.48089144],\n",
       "       [3.33564636, 2.58742839, 3.56474824],\n",
       "       [4.23460852, 0.81456297, 2.66413809],\n",
       "       [2.4162963 , 3.41303307, 3.06063998],\n",
       "       [4.24594114, 1.22585197, 2.22955101],\n",
       "       [4.06572352, 2.45899048, 1.25497551],\n",
       "       [3.5596568 , 2.9471752 , 2.37691002],\n",
       "       [5.35833599, 0.        , 1.65336689],\n",
       "       [4.28139623, 2.28573145, 1.61532203],\n",
       "       [4.70870993, 1.3187706 , 1.63229043],\n",
       "       [4.03285967, 1.91629808, 3.70481389],\n",
       "       [4.72423275, 2.2333984 , 0.40346312],\n",
       "       [3.52100218, 2.31339511, 3.22967593],\n",
       "       [5.39533452, 1.22694275, 0.56216087],\n",
       "       [3.94395278, 1.19666781, 2.61436666],\n",
       "       [2.90049809, 4.39103889, 2.72205688],\n",
       "       [3.64036567, 1.90529287, 3.23950593],\n",
       "       [3.60377004, 1.36269058, 2.40346766],\n",
       "       [3.50390353, 4.05453238, 3.10944244],\n",
       "       [4.30429092, 2.62788335, 1.94695975],\n",
       "       [4.12726872, 1.44707416, 3.06865726],\n",
       "       [3.85386704, 1.37014647, 4.03238248],\n",
       "       [3.30609276, 3.11953196, 2.02165501],\n",
       "       [3.83378928, 1.96700692, 2.52107286],\n",
       "       [4.03476253, 1.75064238, 2.78827944],\n",
       "       [5.30891453, 1.60793013, 0.96711407],\n",
       "       [3.59192434, 1.96490835, 3.9492717 ],\n",
       "       [4.26274897, 3.56869967, 1.00226692],\n",
       "       [4.4468338 , 2.00221092, 2.03825801],\n",
       "       [3.2108864 , 4.6082172 , 1.29197219],\n",
       "       [5.04055704, 0.39447681, 2.25781158],\n",
       "       [5.37355796, 0.52020834, 1.45537994],\n",
       "       [4.84034754, 1.84350292, 1.46058535],\n",
       "       [3.01610003, 4.11124222, 2.1099993 ],\n",
       "       [4.24817307, 1.77455093, 2.26837342],\n",
       "       [3.64956218, 2.54341236, 2.77172104],\n",
       "       [4.1799003 , 2.07620437, 2.83928883],\n",
       "       [4.40052063, 1.49148262, 0.169192  ],\n",
       "       [4.41164632, 2.30697916, 2.20660373],\n",
       "       [4.9524598 , 0.74322447, 2.53235201],\n",
       "       [2.62586448, 3.98677038, 3.99339331],\n",
       "       [4.54038802, 0.35915338, 2.11843691],\n",
       "       [4.11044483, 1.66375348, 2.92573376],\n",
       "       [4.33598358, 1.66879366, 2.06548604],\n",
       "       [4.89991759, 0.24623815, 2.76093022],\n",
       "       [2.00627914, 3.42312278, 5.08043734],\n",
       "       [3.60522455, 0.        , 6.82400422],\n",
       "       [4.95203247, 1.54269924, 0.95453505],\n",
       "       [4.42985731, 0.14566713, 2.10983182],\n",
       "       [3.81514797, 2.44093745, 1.64962987],\n",
       "       [4.02195864, 0.43606266, 2.67806167],\n",
       "       [4.29920878, 0.50168186, 3.86817576]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(3)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.07296713e-02, 2.53667046e-01, 0.00000000e+00, ...,\n",
       "        1.85052941e-03, 8.60877358e-05, 2.82908147e-03],\n",
       "       [5.12774178e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        5.00628750e-04, 9.08554631e-03, 0.00000000e+00],\n",
       "       [2.20278804e-01, 1.27841962e-02, 3.92571938e-03, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "#topic_word.shape\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'you', 'to', 'and', 'it', 'that', 'we'],\n",
       " ['you', 'that', 'it', 'the', 'my', 'and', 'to'],\n",
       " ['you', 'to', 'and', 'is', 'me', 'what', 'it']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-8:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modeling With English Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 17089)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english' )\n",
    "doc_word = vectorizer.fit_transform(episodes.Episode_Text)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madelinevossbrinck/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(125, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(3)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 17089)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['know',\n",
       "  'just',\n",
       "  'don',\n",
       "  'yeah',\n",
       "  'okay',\n",
       "  'oh',\n",
       "  'gonna',\n",
       "  'like',\n",
       "  'hey',\n",
       "  'right'],\n",
       " ['like',\n",
       "  'just',\n",
       "  'oh',\n",
       "  'pawnee',\n",
       "  'know',\n",
       "  'leslie',\n",
       "  'don',\n",
       "  'gonna',\n",
       "  've',\n",
       "  'time'],\n",
       " ['okay',\n",
       "  'going',\n",
       "  'just',\n",
       "  'oh',\n",
       "  'know',\n",
       "  'don',\n",
       "  'like',\n",
       "  'yeah',\n",
       "  'right',\n",
       "  'leslie']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-11:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modeling With Manually Chosen Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 17180)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonwords = ['sorry', 'guys', 'did', 'be', 'get', 'he', 'on', 'been', 'in', 'not', 'are', 'so', 'one', 'to', 'at',\n",
    "            'for', 'but', 'the', 'me', 'your', 'is', 'this', 'if', 'just', 'that', 'of', 'my', 'do', 'was', 'have',\n",
    "            'it', 'and', 'with', 'what', 'like', 'want', 'all', 'gonna', 'we', 'you', 're', 'there', 'here', 'okay',\n",
    "            'no', 'up', 'yeah', 'don', 'they', 'now', 'go', 'well', 'hey', 'uh', 'can', 'who', 'how', 'know', 'as',\n",
    "            'out', 'would', 'really', 'her', 'about', 'look', 'll', 'am', 've', 'let', 'good', 'an', 'from', 'has',\n",
    "            'going', 'oh', 'she', 'or', 'got', 'our', 'take', 'when', 'then', 'will', 'some', 'need', 'had', 'say',\n",
    "            'why', 'could', 'him', 'come', 'should', 'were', 'think', 'might', 'actually', 'them', 'his', 'hi',\n",
    "            'thanks', 'more', 'because', 'please', 'thank', 'make', 'see', 'any', 'every', 'by', 'after', 'back',\n",
    "            'very', 'away', 'being', 'way', 'long', 'else', 'most', 'said', 'too', 'other', 'each', 'new', 'into',\n",
    "            'than', 'still', 'something', 'everything', 'happening', 'start', 'whole', 'talking', 'only', 'anything',\n",
    "            'us', 'tell', 'talk', 'much', 'through', 'thing', 'pretty', 'sir', 'two', 'little', 'doing', 'guy',\n",
    "              'does', 'mean', 'ever', 'yes', 'same', 'put', 'over', 'call', 'day', 'their', 'off', 'these', 'where',\n",
    "              'stop', 'man', 'maybe', 'people', 'down', 'even', 'god', 'first', 'last', 'next', 'old', 'didn', \n",
    "               'capsule', 'having', 'name', 'find', 'ask', 'again', 'lot', 'before']\n",
    "borderline = ['great']\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle'] \n",
    "stopwords = commonwords + names + borderline\n",
    "vectorizer = CountVectorizer(stop_words = stopwords)\n",
    "doc_word = vectorizer.fit_transform(episodes.Episode_Text)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(4)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 17180)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['right', 'time', 'love', 'sure', 'work', 'wait', 'never', 'night'],\n",
       " ['pawnee', 'time', 'eagleton', 'right', 'town', 'work', 'love', 'best'],\n",
       " ['newport', 'bobby', 'campaign', 'city', 'idea', 'right', 'job', 'love'],\n",
       " ['park', 'right', 'parks', 'pit', 'job', 'government', 'department', 'work']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-9:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modeling With Max Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 8654)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonwords = ['sorry', 'guys', 'did', 'be', 'get', 'he', 'on', 'been', 'in', 'not', 'are', 'so', 'one', 'to', 'at',\n",
    "            'for', 'but', 'the', 'me', 'your', 'is', 'this', 'if', 'just', 'that', 'of', 'my', 'do', 'was', 'have',\n",
    "            'it', 'and', 'with', 'what', 'like', 'want', 'all', 'gonna', 'we', 'you', 're', 'there', 'here', 'okay',\n",
    "            'no', 'up', 'yeah', 'don', 'they', 'now', 'go', 'well', 'hey', 'uh', 'can', 'who', 'how', 'know', 'as',\n",
    "            'out', 'would', 'really', 'her', 'about', 'look', 'll', 'am', 've', 'let', 'good', 'an', 'from', 'has',\n",
    "            'going', 'oh', 'she', 'or', 'got', 'our', 'take', 'when', 'then', 'will', 'some', 'need', 'had', 'say',\n",
    "            'why', 'could', 'him', 'come', 'should', 'were', 'think', 'might', 'actually', 'them', 'his', 'hi',\n",
    "            'thanks', 'more', 'because', 'please', 'thank', 'make', 'see', 'any', 'every', 'by', 'after', 'back',\n",
    "            'very', 'away', 'being', 'way', 'long', 'else', 'most', 'said', 'too', 'other', 'each', 'new', 'into',\n",
    "            'than', 'still', 'something', 'everything', 'happening', 'start', 'whole', 'talking', 'only', 'anything',\n",
    "            'us', 'tell', 'talk', 'much', 'through', 'thing', 'pretty', 'sir', 'two', 'little', 'doing', 'guy',\n",
    "              'does', 'mean', 'ever', 'yes', 'same', 'put', 'over', 'call', 'day', 'their', 'off', 'these', 'where',\n",
    "              'stop', 'man', 'maybe', 'people', 'down', 'even', 'god', 'first', 'last', 'next', 'old', 'didn', \n",
    "               'capsule', 'having', 'name', 'find', 'ask', 'again', 'lot', 'before']\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle'] \n",
    "stopwords = commonwords + names \n",
    "vectorizer = CountVectorizer(min_df = 2, max_df = 0.95, stop_words = stopwords)\n",
    "doc_word = vectorizer.fit_transform(episodes.Episode_Text)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(5)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8654)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wait', 'night', 'chris', 'work', 'fine', 'help', 'thought'],\n",
       " ['newport', 'bobby', 'campaign', 'city', 'idea', 'job', 'better'],\n",
       " ['pawnee', 'eagleton', 'town', 'work', 'book', 'everyone', 'joan'],\n",
       " ['park', 'parks', 'pit', 'government', 'department', 'mark', 'meeting'],\n",
       " ['work', 'kids', 'job', 'karate', 'pawnee', 'show', 'life']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-8:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
