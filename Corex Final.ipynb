{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize   \n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode_Split</th>\n",
       "      <th>Episode_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>Hello. Hi. My name is Leslie Knope, and I work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>Well, one of the funner things that we do here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>The Parks Department has so many programs. Jer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>I don't believe it. Oh, my God. It's real. Hey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>In a town as old as Pawnee, there's a lot of h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Character Episode Episode_Split  \\\n",
       "0  Leslie Knope   s1e01         s1e01   \n",
       "1  Leslie Knope   s1e02         s1e02   \n",
       "2  Leslie Knope   s1e03         s1e03   \n",
       "3  Leslie Knope   s1e04         s1e04   \n",
       "4  Leslie Knope   s1e05         s1e05   \n",
       "\n",
       "                                        Episode_Text  \n",
       "0  Hello. Hi. My name is Leslie Knope, and I work...  \n",
       "1  Well, one of the funner things that we do here...  \n",
       "2  The Parks Department has so many programs. Jer...  \n",
       "3  I don't believe it. Oh, my God. It's real. Hey...  \n",
       "4  In a town as old as Pawnee, there's a lot of h...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Leslie_all.pickle','rb') as read_file:\n",
    "    leslie_episodes = pickle.load(read_file)\n",
    "\n",
    "leslie_episodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode_Split</th>\n",
       "      <th>Episode_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>Hello   name  Leslie Knope and  work for the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>Well one  the funner things that   here  Pawne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>The Parks Department has  many programs Jerry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>don believe    God  real Hey Hey Hello Boys  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>town  old  Pawnee there  lot  history  every...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Character Episode Episode_Split  \\\n",
       "0  Leslie Knope   s1e01         s1e01   \n",
       "1  Leslie Knope   s1e02         s1e02   \n",
       "2  Leslie Knope   s1e03         s1e03   \n",
       "3  Leslie Knope   s1e04         s1e04   \n",
       "4  Leslie Knope   s1e05         s1e05   \n",
       "\n",
       "                                        Episode_Text  \n",
       "0  Hello   name  Leslie Knope and  work for the P...  \n",
       "1  Well one  the funner things that   here  Pawne...  \n",
       "2  The Parks Department has  many programs Jerry ...  \n",
       "3   don believe    God  real Hey Hey Hello Boys  ...  \n",
       "4    town  old  Pawnee there  lot  history  every...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leslie_episodes['Episode_Text'] = leslie_episodes['Episode_Text'].str.replace('\\d+', '') # for digits\n",
    "leslie_episodes['Episode_Text'] = leslie_episodes['Episode_Text'].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "leslie_episodes['Episode_Text'] = leslie_episodes['Episode_Text'].str.replace('[^\\w\\s]', '') # for punctuation \n",
    "leslie_episodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode_Split</th>\n",
       "      <th>Episode_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>Tonight is our next monthly community outreach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>Uh, sure, Paul. What can I do for you? Yeah, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>No comment. Hey, Haverford, maybe one day you'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>Go to jail? What's going on? Put it in an emai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>The only reason anybody's going to this thing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Character Episode Episode_Split  \\\n",
       "0  Ron Swanson   s1e01         s1e01   \n",
       "1  Ron Swanson   s1e02         s1e02   \n",
       "2  Ron Swanson   s1e03         s1e03   \n",
       "3  Ron Swanson   s1e04         s1e04   \n",
       "4  Ron Swanson   s1e05         s1e05   \n",
       "\n",
       "                                        Episode_Text  \n",
       "0  Tonight is our next monthly community outreach...  \n",
       "1  Uh, sure, Paul. What can I do for you? Yeah, a...  \n",
       "2  No comment. Hey, Haverford, maybe one day you'...  \n",
       "3  Go to jail? What's going on? Put it in an emai...  \n",
       "4  The only reason anybody's going to this thing ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Ron_all.pickle','rb') as read_file:\n",
    "    ron_episodes = pickle.load(read_file)\n",
    "\n",
    "ron_episodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode_Split</th>\n",
       "      <th>Episode_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>Tonight  our next monthly community outreach p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>sure Paul What can   for you Yeah absolutely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>comment Hey Haverford maybe one day you figur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>jail What going  Put    email Let not blow t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>The only reason anybody going  this thing  bec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Character Episode Episode_Split  \\\n",
       "0  Ron Swanson   s1e01         s1e01   \n",
       "1  Ron Swanson   s1e02         s1e02   \n",
       "2  Ron Swanson   s1e03         s1e03   \n",
       "3  Ron Swanson   s1e04         s1e04   \n",
       "4  Ron Swanson   s1e05         s1e05   \n",
       "\n",
       "                                        Episode_Text  \n",
       "0  Tonight  our next monthly community outreach p...  \n",
       "1   sure Paul What can   for you Yeah absolutely ...  \n",
       "2   comment Hey Haverford maybe one day you figur...  \n",
       "3    jail What going  Put    email Let not blow t...  \n",
       "4  The only reason anybody going  this thing  bec...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ron_episodes['Episode_Text'] = ron_episodes['Episode_Text'].str.replace('\\d+', '') # for digits\n",
    "ron_episodes['Episode_Text'] = ron_episodes['Episode_Text'].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "ron_episodes['Episode_Text'] = ron_episodes['Episode_Text'].str.replace('[^\\w\\s]', '') # for punctuation \n",
    "ron_episodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonwords = ['use', 'own', 'barely', 'bottom'] #['use', 'someday', 'own'] #, 'own', 'went']\n",
    "\n",
    "\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle', 'tommy', 'mark', 'brendanawicz'] \n",
    "\n",
    "\n",
    "nltk_stopwords =  stopwords.words('english')\n",
    "\n",
    "stop_words = list(set(commonwords + names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonwords = ['use', 'own', 'barely', 'bottom'] #['use', 'someday', 'own'] #, 'own', 'went']\n",
    "\n",
    "\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle', 'tommy', 'mark', 'brendanawicz'] \n",
    "\n",
    "\n",
    "#nltk_stopwords =  stopwords.words('english')\n",
    "\n",
    "stop_words = list(set(commonwords + names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=20000, \n",
    "                             stop_words=stop_words, \n",
    "                             tokenizer = LemmaTokenizer(),\n",
    "                             binary=True)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(leslie_episodes.Episode_Text)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Some words never appear (or always appear)\n",
      "0: park,department,director,recreation,live,choice,summer,further,subcommittee,neighborhood\n",
      "1: government,federal,wheel,turning,intern,ready,brainstorming,themselves,moved,truck\n"
     ]
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=2, words=words,\n",
    "                       max_iter=200, verbose = False, seed = 1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=leslie_episodes.Episode_Text, \n",
    "                anchors=[['park'],\n",
    "                         ['government']]\n",
    "                         , anchor_strength=2)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonwords = ['become', 'new', 'even']\n",
    "#['such', 'new', 'wasn', 'also', 'even', 'will', 'this', 'should', 'must', 'out', 'consider', 'old',\n",
    "              # 'really', 'tomorrow', 'ever', 'not', 'recently', 'offering', 'made', 'room']\n",
    "#['new', 'should', 'old', 'such', 'out', 'even', 'while', 'them', 'tomorrow']\n",
    "#['new', 'should', 'old', 'such', 'even', 'seemed', 'while', 'them'] #['even', 'new', 'should', 'wasn', 'such', 'made', 'seemed', 'old']\n",
    "\n",
    "\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle', 'tommy', 'mark', 'brendanawicz'] \n",
    "\n",
    "\n",
    "nltk_stopwords =  stopwords.words('english')\n",
    "\n",
    "stop_words = list(set(names + commonwords + nltk_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=20000, \n",
    "                             stop_words=stop_words, \n",
    "                             tokenizer = LemmaTokenizer(),\n",
    "                             binary=True)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(ron_episodes.Episode_Text)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: park,drive,want,job,killed,nothing,girl,better,person,would\n",
      "1: government,office,taxpayer,meet,large,crap,stand,dollar,hired,wasting\n"
     ]
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=2, words=words,\n",
    "                       max_iter=200, verbose = False, seed = 1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=ron_episodes.Episode_Text, \n",
    "                anchors=[['park'],\n",
    "                         ['government']]\n",
    "                         , anchor_strength=2)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
