{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1e01</td>\n",
       "      <td>Hello. Hi. My name is Leslie Knope, and I work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s1e02</td>\n",
       "      <td>Well, one of the funner things that we do here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s1e03</td>\n",
       "      <td>Okay, now, see, here's a good example of a pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s1e04</td>\n",
       "      <td>So, we've been called out to this hiking trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s1e05</td>\n",
       "      <td>In a town as old as Pawnee, there's a lot of h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Episode                                       Episode_Text\n",
       "0   s1e01  Hello. Hi. My name is Leslie Knope, and I work...\n",
       "1   s1e02  Well, one of the funner things that we do here...\n",
       "2   s1e03  Okay, now, see, here's a good example of a pla...\n",
       "3   s1e04  So, we've been called out to this hiking trail...\n",
       "4   s1e05  In a town as old as Pawnee, there's a lot of h..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('episodes.pickle','rb') as read_file:\n",
    "    episodes = pickle.load(read_file)\n",
    "\n",
    "episodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Model With No Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 17378)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "doc_word = vectorizer.fit_transform(episodes.Episode_Text)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.56481919, 0.16190114, 0.11119044],\n",
       "       [0.90443012, 0.35894005, 1.49111177],\n",
       "       [1.22375574, 0.        , 0.67924268],\n",
       "       [1.61619979, 0.        , 0.        ],\n",
       "       [1.20032145, 0.        , 0.84523206],\n",
       "       [1.72929422, 0.        , 0.        ],\n",
       "       [1.42057966, 0.        , 0.58503703],\n",
       "       [1.42131423, 0.        , 0.        ],\n",
       "       [0.65756064, 0.        , 1.39633948],\n",
       "       [1.81247445, 0.        , 0.        ],\n",
       "       [0.83422089, 0.15140294, 1.26839289],\n",
       "       [1.50043264, 0.02906834, 0.        ],\n",
       "       [1.61759191, 0.        , 0.08706818],\n",
       "       [1.73289868, 0.        , 0.        ],\n",
       "       [0.53791961, 0.39922972, 1.5272149 ],\n",
       "       [1.37883081, 0.        , 0.        ],\n",
       "       [1.45407926, 0.        , 0.        ],\n",
       "       [1.01779671, 0.09974037, 1.18650005],\n",
       "       [2.13232223, 0.01685739, 0.        ],\n",
       "       [1.46047372, 0.        , 0.27021159],\n",
       "       [1.49461473, 0.37065242, 0.13338349],\n",
       "       [1.37877569, 0.        , 0.        ],\n",
       "       [1.16847265, 0.        , 0.94238994],\n",
       "       [1.77102788, 0.        , 0.        ],\n",
       "       [1.27299201, 0.        , 0.58109369],\n",
       "       [1.69500941, 0.80036257, 0.26451874],\n",
       "       [1.03313072, 0.65828993, 0.79453361],\n",
       "       [0.99025144, 0.        , 1.43520626],\n",
       "       [2.31703921, 0.        , 0.2175951 ],\n",
       "       [1.5560226 , 0.05337499, 1.18629593],\n",
       "       [1.2337399 , 0.27480245, 0.67807406],\n",
       "       [1.24471496, 0.        , 0.19814194],\n",
       "       [0.02563913, 0.        , 3.1253184 ],\n",
       "       [1.37570934, 0.02046966, 0.18272644],\n",
       "       [0.79929142, 0.10083083, 1.35013901],\n",
       "       [1.60360454, 0.        , 0.02131375],\n",
       "       [1.07726402, 0.        , 1.50753659],\n",
       "       [1.14267284, 0.80746364, 0.91171511],\n",
       "       [1.82421195, 0.        , 0.        ],\n",
       "       [1.61094941, 0.13194683, 0.        ],\n",
       "       [2.00952126, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 3.50870577],\n",
       "       [2.0292774 , 0.12674197, 0.13191588],\n",
       "       [1.10728193, 0.20377636, 1.07623987],\n",
       "       [1.72475081, 0.29305031, 0.        ],\n",
       "       [1.82844384, 0.17762191, 0.        ],\n",
       "       [1.41267225, 0.53088117, 0.        ],\n",
       "       [1.62943277, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 3.67241982],\n",
       "       [0.91916817, 0.03969681, 1.34415794],\n",
       "       [1.37860795, 0.06242417, 0.25446603],\n",
       "       [2.060821  , 0.01207928, 0.12806497],\n",
       "       [1.65076322, 0.2947016 , 0.32454688],\n",
       "       [1.3003748 , 0.31966195, 0.76473004],\n",
       "       [1.41534443, 0.4020329 , 0.        ],\n",
       "       [1.23280042, 1.1161587 , 0.50503236],\n",
       "       [0.95242313, 1.19796901, 0.51228477],\n",
       "       [0.        , 6.84102312, 0.        ],\n",
       "       [1.54274788, 0.67338306, 0.02244474],\n",
       "       [1.68553552, 0.        , 0.        ],\n",
       "       [1.42622702, 0.55013579, 0.        ],\n",
       "       [1.73840133, 0.31606788, 0.04339771],\n",
       "       [0.        , 5.45600818, 0.86077952],\n",
       "       [1.38240469, 0.30552263, 0.31194561],\n",
       "       [1.32153629, 1.78616133, 0.        ],\n",
       "       [0.43482755, 3.08382425, 0.77680968],\n",
       "       [0.5723435 , 3.35499642, 0.04860177],\n",
       "       [1.01167953, 2.3673273 , 0.04051746],\n",
       "       [1.0849273 , 0.50637729, 1.09023122],\n",
       "       [1.48683612, 0.5326418 , 0.11508031],\n",
       "       [0.94170537, 0.59361469, 1.45727647],\n",
       "       [1.34856012, 0.29437721, 0.49498715],\n",
       "       [1.74583113, 0.02175211, 0.12695105],\n",
       "       [1.73832628, 0.        , 0.19225196],\n",
       "       [1.08041536, 0.87163789, 1.39274954],\n",
       "       [0.        , 0.        , 3.59119655],\n",
       "       [1.63576704, 0.        , 0.        ],\n",
       "       [1.34275186, 0.        , 1.0353176 ],\n",
       "       [1.47871954, 0.24583566, 0.2467603 ],\n",
       "       [1.29215608, 0.        , 1.05444687],\n",
       "       [0.40335525, 0.10510147, 2.7220059 ],\n",
       "       [1.87060487, 0.        , 0.05881969],\n",
       "       [0.82268512, 0.01779292, 1.7875487 ],\n",
       "       [0.71067189, 0.        , 2.28592262],\n",
       "       [1.27070299, 0.51948556, 0.63489597],\n",
       "       [1.460829  , 0.6229498 , 0.39459229],\n",
       "       [1.28616752, 0.09679774, 1.22883286],\n",
       "       [1.85728906, 0.        , 0.04359212],\n",
       "       [1.94596033, 0.0251281 , 0.11028171],\n",
       "       [1.11301366, 0.11811134, 1.82061416],\n",
       "       [2.19669217, 0.        , 2.545544  ],\n",
       "       [0.        , 0.        , 3.35463341],\n",
       "       [0.21870574, 0.03784787, 3.50037191],\n",
       "       [1.57733029, 0.20137497, 0.43659689],\n",
       "       [1.06976405, 0.        , 1.19981476],\n",
       "       [1.28853365, 0.13723029, 1.06602233],\n",
       "       [0.53825356, 0.61187392, 1.82157211],\n",
       "       [1.2004673 , 0.08834467, 1.22708704],\n",
       "       [1.21515522, 0.91233994, 0.97425168],\n",
       "       [1.78793886, 0.11899091, 0.20176037],\n",
       "       [1.75751307, 0.21304404, 0.50607333],\n",
       "       [1.45443116, 0.        , 0.72019204],\n",
       "       [0.32958876, 0.        , 2.81891778],\n",
       "       [0.        , 0.17119745, 3.80986595],\n",
       "       [0.35713012, 0.43540301, 2.54749105],\n",
       "       [1.70238507, 0.        , 0.62227346],\n",
       "       [1.78146492, 0.        , 0.37230159],\n",
       "       [1.24796837, 0.        , 1.16602505],\n",
       "       [1.62793886, 0.        , 0.45609427],\n",
       "       [0.34855202, 0.        , 6.04324547],\n",
       "       [0.42430504, 0.85802619, 2.28873943],\n",
       "       [1.71158798, 0.31892545, 0.45725277],\n",
       "       [0.69647879, 0.62223002, 1.10320441],\n",
       "       [1.56785259, 0.0078721 , 0.33465398],\n",
       "       [1.16251296, 0.5138719 , 0.95680432],\n",
       "       [0.36567857, 0.46119896, 2.49961161],\n",
       "       [1.76157718, 0.01598339, 0.00712533],\n",
       "       [1.46969259, 0.54584417, 0.66500015],\n",
       "       [1.57418127, 0.29812129, 0.01989875],\n",
       "       [0.92133443, 0.        , 1.45467419],\n",
       "       [1.46441882, 0.        , 1.09190977],\n",
       "       [1.46816972, 0.1154246 , 3.59858247]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(3)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51386285, 0.42031663, 0.01952954, ..., 0.1096301 , 0.11497754,\n",
       "        0.01415374],\n",
       "       [0.08720862, 0.27668639, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.0684211 , 0.29347898, 0.01304643, ..., 0.07522886, 0.02236316,\n",
       "        0.02898283],\n",
       "       [0.12775683, 0.14370438, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.06694835, 0.2510498 , 0.        , ..., 0.        , 0.0230101 ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "#topic_word.shape\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'you', 'to', 'and', 'it', 'that', 'we'],\n",
       " ['you', 'that', 'it', 'to', 'the', 'my', 'and'],\n",
       " ['you', 'to', 'and', 'me', 'is', 'what', 'it']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-8:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modeling With English Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 17089)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english' )\n",
    "doc_word = vectorizer.fit_transform(episodes.Episode_Text)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madelinevossbrinck/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(122, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(3)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 17089)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['know', 'just', 'don', 'okay', 'yeah', 'oh', 'like'],\n",
       " ['going', 'okay', 'just', 'oh', 'know', 'don', 'like'],\n",
       " ['like', 'just', 'oh', 'pawnee', 'know', 'gonna', 'don']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-11:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modeling With Manually Chosen Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 17181)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonwords = ['sorry', 'guys', 'did', 'be', 'get', 'he', 'on', 'been', 'in', 'not', 'are', 'so', 'one', 'to', 'at',\n",
    "            'for', 'but', 'the', 'me', 'your', 'is', 'this', 'if', 'just', 'that', 'of', 'my', 'do', 'was', 'have',\n",
    "            'it', 'and', 'with', 'what', 'like', 'want', 'all', 'gonna', 'we', 'you', 're', 'there', 'here', 'okay',\n",
    "            'no', 'up', 'yeah', 'don', 'they', 'now', 'go', 'well', 'hey', 'uh', 'can', 'who', 'how', 'know', 'as',\n",
    "            'out', 'would', 'really', 'her', 'about', 'look', 'll', 'am', 've', 'let', 'good', 'an', 'from', 'has',\n",
    "            'going', 'oh', 'she', 'or', 'got', 'our', 'take', 'when', 'then', 'will', 'some', 'need', 'had', 'say',\n",
    "            'why', 'could', 'him', 'come', 'should', 'were', 'think', 'might', 'actually', 'them', 'his', 'hi',\n",
    "            'thanks', 'more', 'because', 'please', 'thank', 'make', 'see', 'any', 'every', 'by', 'after', 'back',\n",
    "            'very', 'away', 'being', 'way', 'long', 'else', 'most', 'said', 'too', 'other', 'each', 'new', 'into',\n",
    "            'than', 'still', 'something', 'everything', 'happening', 'start', 'whole', 'talking', 'only', 'anything',\n",
    "            'us', 'tell', 'talk', 'much', 'through', 'thing', 'pretty', 'sir', 'two', 'little', 'doing', 'guy',\n",
    "              'does', 'mean', 'ever', 'yes', 'same', 'put', 'over', 'call', 'day', 'their', 'off', 'these', 'where',\n",
    "              'stop', 'man', 'maybe', 'people', 'down', 'even', 'god', 'first', 'last', 'next', 'old', 'didn', \n",
    "               'capsule', 'having', 'name', 'find', 'ask', 'again', 'lot', 'before']\n",
    "borderline = ['great']\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle'] \n",
    "stopwords = commonwords + names + borderline\n",
    "vectorizer = CountVectorizer(stop_words = stopwords)\n",
    "doc_word = vectorizer.fit_transform(episodes.Episode_Text)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(4)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 17181)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['right', 'time', 'love', 'great', 'sure', 'wait', 'never', 'work'],\n",
       " ['pawnee', 'time', 'right', 'love', 'eagleton', 'town', 'work', 'great'],\n",
       " ['newport', 'bobby', 'campaign', 'city', 'idea', 'great', 'right', 'job'],\n",
       " ['park', 'right', 'great', 'parks', 'pit', 'government', 'department', 'job']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-9:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modeling With Max Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 8654)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonwords = ['sorry', 'guys', 'did', 'be', 'get', 'he', 'on', 'been', 'in', 'not', 'are', 'so', 'one', 'to', 'at',\n",
    "            'for', 'but', 'the', 'me', 'your', 'is', 'this', 'if', 'just', 'that', 'of', 'my', 'do', 'was', 'have',\n",
    "            'it', 'and', 'with', 'what', 'like', 'want', 'all', 'gonna', 'we', 'you', 're', 'there', 'here', 'okay',\n",
    "            'no', 'up', 'yeah', 'don', 'they', 'now', 'go', 'well', 'hey', 'uh', 'can', 'who', 'how', 'know', 'as',\n",
    "            'out', 'would', 'really', 'her', 'about', 'look', 'll', 'am', 've', 'let', 'good', 'an', 'from', 'has',\n",
    "            'going', 'oh', 'she', 'or', 'got', 'our', 'take', 'when', 'then', 'will', 'some', 'need', 'had', 'say',\n",
    "            'why', 'could', 'him', 'come', 'should', 'were', 'think', 'might', 'actually', 'them', 'his', 'hi',\n",
    "            'thanks', 'more', 'because', 'please', 'thank', 'make', 'see', 'any', 'every', 'by', 'after', 'back',\n",
    "            'very', 'away', 'being', 'way', 'long', 'else', 'most', 'said', 'too', 'other', 'each', 'new', 'into',\n",
    "            'than', 'still', 'something', 'everything', 'happening', 'start', 'whole', 'talking', 'only', 'anything',\n",
    "            'us', 'tell', 'talk', 'much', 'through', 'thing', 'pretty', 'sir', 'two', 'little', 'doing', 'guy',\n",
    "              'does', 'mean', 'ever', 'yes', 'same', 'put', 'over', 'call', 'day', 'their', 'off', 'these', 'where',\n",
    "              'stop', 'man', 'maybe', 'people', 'down', 'even', 'god', 'first', 'last', 'next', 'old', 'didn', \n",
    "               'capsule', 'having', 'name', 'find', 'ask', 'again', 'lot', 'before']\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle'] \n",
    "stopwords = commonwords + names \n",
    "vectorizer = CountVectorizer(min_df = 2, max_df = 0.95, stop_words = stopwords)\n",
    "doc_word = vectorizer.fit_transform(episodes.Episode_Text)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(5)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8654)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wait', 'night', 'chris', 'work', 'fine', 'help', 'thought'],\n",
       " ['newport', 'bobby', 'campaign', 'city', 'idea', 'job', 'better'],\n",
       " ['pawnee', 'eagleton', 'town', 'work', 'book', 'everyone', 'joan'],\n",
       " ['park', 'parks', 'pit', 'government', 'department', 'mark', 'meeting'],\n",
       " ['work', 'kids', 'job', 'karate', 'pawnee', 'show', 'life']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-8:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
