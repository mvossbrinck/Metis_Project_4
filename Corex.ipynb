{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize   \n",
    "from nltk.stem import WordNetLemmatizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode_Split</th>\n",
       "      <th>Episode_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>Tonight is our next monthly community outreach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>Uh, sure, Paul. What can I do for you? Yeah, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>No comment. Hey, Haverford, maybe one day you'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>Go to jail? What's going on? Put it in an emai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ron Swanson</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>The only reason anybody's going to this thing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Character Episode Episode_Split  \\\n",
       "0  Ron Swanson   s1e01         s1e01   \n",
       "1  Ron Swanson   s1e02         s1e02   \n",
       "2  Ron Swanson   s1e03         s1e03   \n",
       "3  Ron Swanson   s1e04         s1e04   \n",
       "4  Ron Swanson   s1e05         s1e05   \n",
       "\n",
       "                                        Episode_Text  \n",
       "0  Tonight is our next monthly community outreach...  \n",
       "1  Uh, sure, Paul. What can I do for you? Yeah, a...  \n",
       "2  No comment. Hey, Haverford, maybe one day you'...  \n",
       "3  Go to jail? What's going on? Put it in an emai...  \n",
       "4  The only reason anybody's going to this thing ...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Ron_all.pickle','rb') as read_file:\n",
    "    ron_episodes = pickle.load(read_file)\n",
    "\n",
    "ron_episodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "ron_episodes['Episode_Text'] = ron_episodes['Episode_Text'].str.replace('\\d+', '') # for digits\n",
    "ron_episodes['Episode_Text'] = ron_episodes['Episode_Text'].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "ron_episodes['Episode_Text'] = ron_episodes['Episode_Text'].str.replace('[^\\w\\s]', '') # for punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonwords = ['sorry', 'guys', 'did', 'be', 'get', 'he', 'on', 'been', 'in', 'not', 'are', 'so', 'one', 'to', 'at',\n",
    "            'for', 'but', 'the', 'me', 'your', 'is', 'this', 'if', 'just', 'that', 'of', 'my', 'do', 'was', 'have',\n",
    "            'it', 'and', 'with', 'what', 'like', 'want', 'all', 'gonna', 'we', 'you', 're', 'there', 'here', 'okay',\n",
    "            'no', 'up', 'yeah', 'don', 'they', 'now', 'go', 'well', 'hey', 'uh', 'can', 'who', 'how', 'know', 'as',\n",
    "            'out', 'would', 'really', 'her', 'about', 'look', 'll', 'am', 've', 'let', 'good', 'an', 'from', 'has',\n",
    "            'going', 'oh', 'she', 'or', 'got', 'our', 'take', 'when', 'then', 'will', 'some', 'need', 'had', 'say',\n",
    "            'why', 'could', 'him', 'come', 'should', 'were', 'think', 'might', 'actually', 'them', 'his', 'hi',\n",
    "            'thanks', 'more', 'because', 'please', 'thank', 'make', 'see', 'any', 'every', 'by', 'after', 'back',\n",
    "            'very', 'away', 'being', 'way', 'long', 'else', 'most', 'said', 'too', 'other', 'each', 'new', 'into',\n",
    "            'than', 'still', 'something', 'everything', 'happening', 'start', 'whole', 'talking', 'only', 'anything',\n",
    "            'us', 'tell', 'talk', 'much', 'through', 'thing', 'pretty', 'sir', 'two', 'little', 'doing', 'guy',\n",
    "              'does', 'mean', 'ever', 'yes', 'same', 'put', 'over', 'call', 'day', 'their', 'off', 'these', 'where',\n",
    "              'stop', 'man', 'maybe', 'people', 'down', 'even', 'god', 'first', 'last', 'next', 'old', 'didn', \n",
    "               'capsule', 'having', 'name', 'find', 'ask', 'again', 'lot', 'before', 'must', 'wasn', 'use']\n",
    "\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle', 'tommy', 'mark'] \n",
    "\n",
    "\n",
    "nltk_stopwords =  stopwords.words('english')\n",
    "\n",
    "stop_words = list(set(names + nltk_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonwords = ['cream', 'cheese', 'want', 'new', 'large', 'made', 'small', 'throat', 'old', 'feel' ,'must']\n",
    "\n",
    "\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle', 'tommy', 'mark'] \n",
    "\n",
    "\n",
    "nltk_stopwords =  stopwords.words('english')\n",
    "\n",
    "stop_words = list(set(names + nltk_stopwords + commonwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=20000, \n",
    "                             stop_words=stop_words, tokenizer = LemmaTokenizer(),\n",
    "                             binary=True)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(ron_episodes.Episode_Text)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: park,leave,took,adult,rest,fine,honestly,shotgun,two,hello\n",
      "1: government,taxpayer,meet,project,crap,ridiculous,office,win,right,drink\n"
     ]
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=2, words=words,\n",
    "                       max_iter=200, verbose = False, seed = 1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=ron_episodes.Episode_Text, \n",
    "                anchors=[['park'],\n",
    "                         ['government']]\n",
    "                         , anchor_strength=2)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: park,leave,took,adult,rest,fine,honestly,shotgun,two,hello\n",
      "1: government,taxpayer,meet,project,crap,ridiculous,office,win,right,drink\n"
     ]
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=2, words=words,\n",
    "                       max_iter=200, verbose = False, seed = 1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=ron_episodes.Episode_Text, \n",
    "                anchors=[['park'],\n",
    "                         ['government']]\n",
    "                         , anchor_strength=2)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode_Split</th>\n",
       "      <th>Episode_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>s1e01</td>\n",
       "      <td>Hello. Hi. My name is Leslie Knope, and I work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>s1e02</td>\n",
       "      <td>Well, one of the funner things that we do here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>s1e03</td>\n",
       "      <td>The Parks Department has so many programs. Jer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>s1e04</td>\n",
       "      <td>I don't believe it. Oh, my God. It's real. Hey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leslie Knope</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>s1e05</td>\n",
       "      <td>In a town as old as Pawnee, there's a lot of h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Character Episode Episode_Split  \\\n",
       "0  Leslie Knope   s1e01         s1e01   \n",
       "1  Leslie Knope   s1e02         s1e02   \n",
       "2  Leslie Knope   s1e03         s1e03   \n",
       "3  Leslie Knope   s1e04         s1e04   \n",
       "4  Leslie Knope   s1e05         s1e05   \n",
       "\n",
       "                                        Episode_Text  \n",
       "0  Hello. Hi. My name is Leslie Knope, and I work...  \n",
       "1  Well, one of the funner things that we do here...  \n",
       "2  The Parks Department has so many programs. Jer...  \n",
       "3  I don't believe it. Oh, my God. It's real. Hey...  \n",
       "4  In a town as old as Pawnee, there's a lot of h...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Leslie_all.pickle','rb') as read_file:\n",
    "    leslie_episodes = pickle.load(read_file)\n",
    "\n",
    "leslie_episodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonwords = ['wheel', 'turning','use', 'barely', 'bottom', 'truck', 'bird', 'page']\n",
    "\n",
    "\n",
    "names = ['leslie', 'knope', 'ron', 'swanson', 'ben', 'wyatt', 'april', 'ludgate', 'tom', 'haverford', \n",
    "         'ann', 'perkins', 'andy', 'dwyer', 'jerry', 'gergich', 'donna', 'meagle', 'tommy', 'mark'] \n",
    "\n",
    "\n",
    "nltk_stopwords =  stopwords.words('english')\n",
    "\n",
    "stop_words = list(set(nltk_stopwords + names+ commonwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=20000, \n",
    "                             stop_words=stop_words, tokenizer = LemmaTokenizer(),\n",
    "                             binary=True)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(leslie_episodes.Episode_Text)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Some words never appear (or always appear)\n",
      "0: park,director,recreation,department,choice,year,system,sell,neighborhood,summer\n",
      "1: government,ready,gun,48,intern,staff,except,notice,people,budget\n"
     ]
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=2, words=words,\n",
    "                       max_iter=200, verbose=False, seed=2)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=leslie_episodes.Episode_Text, \n",
    "                anchors=[['park'],\n",
    "                        ['government']]\n",
    "                         , anchor_strength=2)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello. Hi. My name is Leslie Knope, and I work for the Parks and Recreation Department. Can I ask you a few questions? Would you say that you are, \"Enjoying yourself and having fun, having a moderate amount of fun and somewhat enjoying yourself, or having no fun and no enjoyment?\" I\\'m gonna put a lot of fun. Sir, this is a children\\'s slide. You\\'re not allowed to sleep in here. You know, when I first tell people that I work in the government, they say, \"Oh.\" \"The government.\" \"The government stinks.\" \"The lines are too long at the DMV.\" But now things have changed. People need our help. And it feels good to be needed. Could you put your arms to your side? And that might help you slide down a little easier. Do you want to come this way? Okay, we\\'re gonna need you to get out. Get out of the slide. Okay? Here we go! Okay, wake up. Here we go. Out of the slide. You know, government isn\\'t just a boys\\' club anymore. Women are everywhere. It\\'s a great time to be a woman in politics. Hillary Clinton, Sarah Palin, me, Nancy Pelosi. We did it! You know, I like to tell people, you know, \"Get on board and buckle up, because my ride\\'s gonna be a big one.\" And if you get motion sickness, you know, put your head between your knees \\'cause Leslie Knope\\'s stopping for no one. And that is tonight. Right. This is a great thing for you guys to see. This is where the rubber of government meets the road of actual human beings. When I go through these doors, I need to be on. Like the White House Press Secretary. Are you ready? Okay. Here we go. It\\'s locked. Okay. Here we go. Thank you so much for coming. What an amazing turnout. My name is Leslie Knope. I am the deputy director of the Parks and Recreation Department, and tonight we\\'re gonna be taking some of your questions as-- Hello? We\\'re having a meeting in here. So, take two. I\\'m Leslie Knope, and with me is department member Tom Haverford. We are here to answer any and all of your questions, so fire away. I don\\'t like obscenities just as much as you don\\'t like them. Right. These people are members of a community that care about where they live, so what I hear when I\\'m being yelled at is people caring loudly at me. Thank you so much, Barry. Always great to have you here. Anyone else who would like to contribute? Excellent. That sounds like a good idea. Tell us about that. Oh. Twelve months, yes. Go on. Okay. I\\'ll do something about it. Yes, we-- I will help you. It\\'s more than a promise. It\\'s a pinky promise. I pinky promise all of you that I will help, and I will go to that location tomorrow, and we will fill in that pit, and then when that\\'s done, we\\'re gonna put a park on the land. Well, I\\'ve worked at the Parks Department for six years, and I\\'ve handled a lot of things that I\\'m proud of. Recently, I led a city-wide drive to disinfect the sandbox sand after we had those problems with the cats. But this pit, the chance to build a whole new park from scratch, this could be my Hoover Dam. Morning. You were talking to the mayor? Tom and I work really well together. We\\'re both outsiders. I\\'m a woman, he\\'s a... I think he\\'s a Libyan. Okay, brainstorm. How do we make this park happen? No, parks are not a priority. I need more firepower. I need bigger guns. You know what I need to do? Form a committee. Right? Yeah, \\'cause committees are power, and committees make things happen. Committees are the lifeblood of our democratic system. That\\'s really good. Write that down. From time to time, when I think of an eloquent saying or a phrase, I have Tom write it down. He\\'s collecting them for my memoirs. Okay, read it back to me. Hmm. Sounded better when I said it. It\\'s still good, though. Okay, I have an idea. What about bringing Mark on board? Which Mark? Mark Brendanawicz. Which Mark? Well, if you want something done in this town, you call Mark Brendanawicz because, you know, he\\'s a city planner, but he\\'s more than that. He\\'s kind of like a fixer. He fixes things. He\\'s a smart, capable guy. He just-- He knows where the bodies are buried. What\\'s up, Brendanawicz? You crazy old Polish person. City Hall is like a locker room, and you gotta get in there, and you gotta snap towels at people, and you gotta give them the business, and if you can\\'t take it, you know, you... Then you can\\'t take it. You gotta leave the locker room. Let\\'s get down to brass tacks. I know you don\\'t have a lot of time and I want to thank you for meeting me today. Well, thank you for clearing your schedule. You know this lot that I\\'m talking about, right? What would you say if I told you that I was thinking about turning it into a park? What? Why? Really? It sounds like you\\'re telling me to go for it. I can do this. I just need a little help. Could you do me a favor, for old times\\' sake? Mark and I-- It\\'s complicated. When you work closely with someone and you share similar interests and you have a similar world view and you\\'re passionate about the same things, things can happen. We slept together. It\\'s Ms. Perkins\\' house. I\\'m here. Safety. You remember Tom from last night. And this is our college intern, April. She\\'s going to be documenting our fact finding mission. This must be our hero. The man heard \\'round the world. How you doing, son? I\\'m Leslie Knope. And the entire government of Pawnee would like to let you know that we will do everything we can to help you. Of course. Oh, my God. How did we let this happen? Dream with me for a second, Ann. Doesn\\'t this neighborhood deserve a first-class park? Imagine a shiny new playground with a jungle gym and swings, pool, tennis courts, volleyball courts, racquetball courts, basketball court, regulation football field. We could put an amphitheatre over there with Shakespeare in the Park. We could do some of those things. It\\'s gonna take a little extra work. But why not try? Me, too. I\\'m going in. Don\\'t worry. I have a hard hat on. Yeah. April, document this. The key to any factfinding mission is to get right into the battle zone, you know? It\\'s like George Bush when he flew over New Orleans or Richard Nixon when he went to China to see what the Chinese were up to. No! No. Mmmmmm. I\\'m fine. Good thing I was wearing that hard hat. After my head hit that rod. Well, at least my boss will listen to me now that I broke my clavicle. It is. Do you have one of those neck foam collar brace things? Honestly, my clavicle\\'s broken. Ooh! Are pancakes being made? Thank you. Ron, please. Come on, Ron. I\\'ve been a loyal foot soldier. Give me my shot. Let me have Lot 48. Ron, I don\\'t know how to explain this to you. When you\\'ve been down in the pit-- Have you been in the pit? Well, I have. When I visited the bottom of the pit on a fact finding mission. And when you\\'re down there, you get some perspective about what it all means. And let me tell you something, Ron. What it means is I want this subcommittee. I like the sound of that definitely. I\\'m gonna leave before you change your mind. Mr. Swanson, I presume. Lot 46 thoughts? Yes? No? Me? Park? Giving the park to me? All right, you guys. All right, all right. I\\'ll ask him. Everybody wants to know what your decision is. Someone on the phone about the park. You know, I don\\'t think I even want it. Oh man. My clavicle\\'s still really hurting me. So this was built in 1935, it\\'s called Pioneer Hall. And a little trivia, it is one of the first structures in America to ever have locks. Oh, yeah. This is our crown jewel. It\\'s one of our best murals. It depicts the very famous battle at Conega Creek. We have a lot of children visit, so often we have to cover up the more gruesome parts with a poster. Yes, it is. So, what do you want to see? The DMV? Animal control? Or we could-- That\\'s great! That\\'s so exciting! This is huge. I\\'m barely 34, and I\\'ve already landed a Parks Department exploratory subcommittee. I\\'m a rocket ship. Hey. Isn\\'t it great? Thank you. I\\'m so excited. It\\'s exciting, isn\\'t it? Yeah. Should I call a press conference now, or-- You know what? America is awesome. It\\'s so full of hope and small towns and big cities and real people and delicious beverages and hot guys. You just never know when opportunity is gonna strike. You gotta be ready for it. Are you excited? Yeah! Soul sista, soul sista Gonna get your phone, sista Sweet Lady Marmalard',\n",
       "  0.0),\n",
       " ('No, I don\\'t. I\\'m sorry. That was weird. Okay, bye. Oh, this is Lester Kanopf. No, you know who it-- Okay, bye. I panicked. We should go. We have a lot of stuff to do and the meter\\'s still running on that cab, so chop chop. Yeah. Okay, everyone, welcome to the very last Unity concert planning meeting. Andy, you are in charge. This is your show. Take it away. You\\'re right. The name is too long. I was picturing bigger hats. Can the Parks and Rec people hang back for a second? Um The reason I wanted you guys to stick around is, I wanted to tell youâ\\x80¦ That I love and admire you. A while ago, I was offered a job at the national parks service, and it\\'s a great opportunity, but it means that I\\'ll have to move to Illinois. And I took the job. Leslie Knope, champion of the Pawnee Eagleton merger, \"our most faithful citizen.\" \"She never abandoned us.\" Oh, boy. \"\\'Only a moron would ever live anywhere other than Pawnee, Indiana.\\' Leslie Knope, multiple occasions.\" This is so touching, you guys. I am crying out of happiness and sadness and gratitude and because I\\'m carrying triplets and for a fifth reason that I can\\'t figure out. Yeah. Oh, wow. What is that? Crazy, right? Oh, so does that mean that there\\'s two openings left? Because I happen to know some of the most dedicated civil servants and greatest people to ever walk the planet earth. Ron, I have to ask you something, and I want you to consider it, okay? Really consider it. How would you feel about leaving Pawnee and moving to Chicago? Hold on, come on, I\\'m not done. You\\'d be working for the federal government. You know what, excuse me for wanting my dear friend and ethical mentor to accompany me on the adventure of a lifetime. I hope you like deep dish pizza, because there\\'s gonna be a lot more of it in Chicago, where we\\'re all gonna be moving. Come on, guys, take a risk. Live on the edge. Life is an adventure. Well, you know, you owe me for that pizza. Everybody turned me down but Larry. Yeah. Man, I\\'m gonna miss Pawnee. I wish I could stay, you know, keep an eye on it, raise my kids here. And let\\'s be honest, am I ever gonna find a better breakfast than JJ\\'s Diner? Thank you, Ron. That\\'s very sweet. Oh, my God. I can have everything I want! Thank you. Oh, and by the way, don\\'t think that we are not discussing Duke silver. When were you going to tell me about that? Unbelievable! I am so furious at you, but I\\'ve already forgiven you, and you need to teach me how to play the saxophone. Okay, bye. No time for small talk. I think the best version of me working as Midwest regional director is not in Chicago. It\\'s right here in Pawnee. Look, Pawnee is a town on the rise, and national parks could get in on the ground floor. It\\'s the best option, hands down. Sometimes you have to make the hardest climb to see the most beautiful sunrise. I read that once on an old lady\\'s decorative pillow. But it is really how I feel today. I\\'ve climbed a very weird and rocky mountain, and it was a pain in the ass, and my legs are tired, and I\\'m starving, but the sun is rising over a sea of love and waffles and possibility. So I\\'m just gonna relax and take a deep breath and enjoy this view for as long as I possibly can. Call Ken and Rebecca, and no statements to the press unless I personally release them. We are on a media lockdown. Where is Ed with the file? Ed! Ed, you\\'re a nice guy, but you\\'re the most incompetent person I\\'ve ever word with, and that includes Terry. Clean out your desk. You\\'re fired. Cancel my flight to South Dakota. We\\'ll do it next month. Babe, what\\'s our play here? But honey, tonight\\'s your big night. Hey, guys! Mommy and daddy had to do a little work, and you\\'re gonna have a fun play date with Uncle Andy and Aunty April, okay? One day, in the distant future, things will be calm and normal, right? Not at all. But that\\'s never stopped us before.',\n",
       "  0.0)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_top_docs(topic=1, n_docs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Some words never appear (or always appear)\n",
      "0: government,month,losing,taken,people,judge,somewhere,chapter,monster,emailing\n",
      "1: government,intern,bird,park,community,prepared,vendor,priority,term,director\n"
     ]
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=2, words=words,\n",
    "                       max_iter=200, verbose=False, seed=1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=leslie_episodes.Episode_Text, \n",
    "                anchors=[['government'],\n",
    "                        ['government']]\n",
    "                         , anchor_strength=2)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=200000,\n",
    "                             stop_words=stopwords, #token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                             binary=True)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(ron_episodes.Episode_Text)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: parks,pounds,waste,face,three,citizen,remember,seven,hole,self\n",
      "1: government,right,person,dollars,stand,tax,wasting,speech,offering,40\n"
     ]
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=2, words=words,\n",
    "                       max_iter=200, verbose=False, seed=5)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=ron_episodes.Episode_Text, \n",
    "                anchors=[['parks'],\n",
    "                        ['government']]\n",
    "                         , anchor_strength=2)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
